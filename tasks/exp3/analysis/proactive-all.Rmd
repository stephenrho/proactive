---
title: "Proactive online - age group by interval by distraction"
output:
  pdf_document: default
  html_document: default
urlcolor: blue
---

```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = F, message = F, warning = F)

options(mc.cores = parallel::detectCores())

library(plyr)
library(ez)
library(lme4)
library(psych)
library(brms)

source("../../exp1/analysis/useful_functions.R")

# read
e1_wm = read.csv("../../exp1/analysis/exp1_wm.csv", stringsAsFactors = F)
e1_learn = read.csv("../../exp1/analysis/exp1_learn.csv", stringsAsFactors = F)

e2_wm = read.csv("../../exp2/analysis/exp2_wm.csv", stringsAsFactors = F)
e2_learn = read.csv("../../exp2/analysis/exp2_learn.csv", stringsAsFactors = F)
e2_search = read.csv("../../exp2/analysis/exp2_search.csv", stringsAsFactors = F)

e3_search_dist = read.csv("exp3_search_dist.csv", stringsAsFactors = F)
e3_wm_dist = read.csv("exp3_wm_dist.csv", stringsAsFactors = F)
e3_learn_dist = read.csv("exp3_learn_dist.csv", stringsAsFactors = F)

e3_wm_blan = read.csv("exp3_wm_blan.csv", stringsAsFactors = F)
e3_learn_blan = read.csv("exp3_learn_blan.csv", stringsAsFactors = F)

## info
e1_info_y = read.csv("../../exp1/analysis/prolific_export_5f035e5afe130c270d6ae6dd-younger.csv")
e1_info_o = read.csv("../../exp1/analysis/prolific_export_5f073de81c76c3308c0e4fb3-older.csv")

e2_info_y = read.csv("../../exp2/analysis/prolific_export_5f341be081b9052c55068110-younger.csv")
e2_info_o = read.csv("../../exp2/analysis/prolific_export_5f5126bb654d4b30ee6923d8-older.csv")

e3_dist_info_y = read.csv("prolific_export_5f47c29a48bd2a1e651a6eb7-younger-dist.csv")
e3_blan_info_y = read.csv("prolific_export_5f47c0b9b035471e11593a5c-younger-blan.csv")
e3_dist_info_o = read.csv("prolific_export_5f599a131af4471f3d752b7b-older-dist.csv")
e3_blan_info_o = read.csv("prolific_export_5f5adea66120081ea0f57a61-older-blan.csv")

# new columns 
e1_wm$distraction = e1_learn$distraction = "no"
e2_wm$distraction = e2_learn$distraction = "yes"

e1_info_y$distraction = e1_info_o$distraction = "no"
e2_info_y$distraction = e2_info_o$distraction = "yes"

e1_wm$interval = e1_learn$interval = "2 s"
e2_wm$interval = e2_learn$interval = "2 s"

e1_info_y$interval = e1_info_o$interval = "2 s"
e2_info_y$interval = e2_info_o$interval = "2 s"

e3_wm_dist$distraction = e3_learn_dist$distraction = "yes"
e3_wm_blan$distraction = e3_learn_blan$distraction = "no"

e3_dist_info_y$distraction = e3_dist_info_o$distraction = "yes"
e3_blan_info_y$distraction = e3_blan_info_o$distraction = "no"

e3_wm_dist$interval = e3_learn_dist$interval = "10 s"
e3_wm_blan$interval = e3_learn_blan$interval = "10 s"

e3_dist_info_y$interval = e3_dist_info_o$interval = "10 s"
e3_blan_info_y$interval = e3_blan_info_o$interval = "10 s"

# combine
wm_cols = Reduce(intersect, list(colnames(e1_wm), 
                                 colnames(e2_wm), 
                                 colnames(e3_wm_dist), 
                                 colnames(e3_wm_blan)))

learn_cols = Reduce(intersect, list(colnames(e1_learn), 
                                 colnames(e2_learn), 
                                 colnames(e3_learn_dist), 
                                 colnames(e3_learn_blan)))

info_cols = Reduce(intersect, list(colnames(e1_info_y),
                                   colnames(e1_info_o),
                                   colnames(e2_info_y),
                                   colnames(e2_info_o),
                                   colnames(e3_dist_info_y),
                                   colnames(e3_dist_info_o),
                                   colnames(e3_blan_info_y),
                                   colnames(e3_blan_info_o)))

wm_dat = rbind(e1_wm[,wm_cols], 
               e2_wm[,wm_cols], 
               e3_wm_dist[,wm_cols], 
               e3_wm_blan[,wm_cols])

learn_dat = rbind(e1_learn[,learn_cols], 
               e2_learn[,learn_cols], 
               e3_learn_dist[,learn_cols], 
               e3_learn_blan[,learn_cols])

info = rbind(e1_info_y[,info_cols], 
             e1_info_o[,info_cols],
             e2_info_y[,info_cols],
             e2_info_o[,info_cols],
             e3_dist_info_y[,info_cols],
             e3_dist_info_o[,info_cols],
             e3_blan_info_y[,info_cols],
             e3_blan_info_o[,info_cols])

info = subset(info, participant_id %in% unique(wm_dat$participant))

info$group = ifelse(info$age > 50, "older", "younger")

groups = c("younger", "older")
distractions = c("no", "yes")
intervals = c("2 s", "10 s")

ids = list()
for (i in intervals){
  for (d in distractions){
    for (g in groups){
      ids[[i]][[d]][[g]] = unique(wm_dat$participant[with(wm_dat, group==g & distraction==d & interval==i)])
    }
  }
}

### relax spell check...
# e.g., if 70% of letters match, consider correct

# prop_match = function(vec1, vec2){
#   # proportion of strings in vec1 in vec2
#   # ignoring duplicates in either
#   # i.e., runner --> prune = .8
#   
#   stopifnot(length(vec1) == length(vec2))
#   
#   str1 = strsplit(vec1, split = "")
#   str2 = strsplit(vec2, split = "")
#   
#   out = unlist(lapply(1:length(vec1), FUN = function(i) sum(str1[[i]][!duplicated(str1[[i]])] %in% str2[[i]][!duplicated(str2[[i]])])/length(str2[[i]][!duplicated(str2[[i]])]) ))
#   
#   out[is.na(vec2)] = NA
#   
#   return(out)
# }

# learn_dat$prop_lett = with(learn_dat, prop_match(recalled, word))
# wm_dat$prop_lett = with(wm_dat, prop_match(recalled, word))

# subset(learn_full, prop_lett > 1)
# subset(learn_full, prop_lett > .7 & prop_lett < .9)
# hist(learn_full$prop_lett)

### figure out types of errors

# intrusions from learned associates
# should have kept track of previous associates... will have to reverse eng

wm_dat$prev_assoc = NA

for (i in 1:nrow(wm_dat)){
  if (wm_dat$item_type[i] %in% c("mis-match", "old-new")){
    s = wm_dat$participant[i]; im = wm_dat$image[i]
    
    prev_words = learn_dat$word[learn_dat$participant == s & learn_dat$image == im]
    if (length(unique(prev_words)) == 1){
      wm_dat$prev_assoc[i] = prev_words[1]
    } else{
      cat("row", i, "different words...\n")
    }
    
  }
}

wm_dat$ltm_intru = with(wm_dat, as.integer(recalled == prev_assoc))

wm_dat$ltm_intru[is.na(wm_dat$recalled) & !is.na(wm_dat$prev_assoc)] = 0 # replace NAs with zero when noting was recalled

# wm_dat$ltm_prop_lett = with(wm_dat, prop_match(recalled, prev_assoc))

# mean(wmmain_dat$ltm_intru, na.rm = T)
# mean(wmmain_dat$ltm_prop_lett == 1, na.rm = T)

# type of errors...

wm_dat$study_pos = wm_dat$study_pos + 1

n_trials = max(wm_dat$trial_no)

S = unique(wm_dat$participant)

wm_dat$resp_type = NA
wm_dat$tran_dist = NA

for (s in 1:length(S)){
  for (t in 1:n_trials){
    for (i in 1:4){
      r = with(wm_dat, which(participant == S[s] & trial_no == t & study_pos == i) ) # row
      w = wm_dat$word[r] # studied 
      re = wm_dat$recalled[r] # recalled
      
      # first, check if correct or from ltm set
      if (wm_dat$recall_acc[r] == 1){
        wm_dat$resp_type[r] = "correct"
      } else if (wm_dat$ltm_intru[r] %in% 1){
        wm_dat$resp_type[r] = "ltm"
      } else if (is.na(re) | re == "" | re == "?") {
        wm_dat$resp_type[r] = "omission"
      } else{
        # not correct or an ltm intrusion
        nt = wm_dat$word[with(wm_dat, participant == S[s] & trial_no == t & word != w)] # non targets
        pt = rep("", 4) # previous trial items (if there were any)
        if (t > 1){
          pt = wm_dat$word[with(wm_dat, participant == S[s] & trial_no == t-1)]
        }
        
        if (re %in% nt){
          # was a non-target from within that trial recalled?
          wm_dat$resp_type[r] = "within"
          # calculate transposition distance
          # position studied - position of recalled item in sequence
          # e.g., + 1 equals next item in the sequence
          wm_dat$tran_dist[r] = i - wm_dat$study_pos[with(wm_dat, participant == S[s] & trial_no == t & word == re)]
        } else if (re %in% pt){
          # was an item from a previous trial recalled?
          wm_dat$resp_type[r] = "previous"
        } else {
          # if not, must be an extra list error...
          wm_dat$resp_type[r] = "extra"
        }
      }
    }
  }
}

wmresps_agg = ddply(wm_dat, c("participant", "group", "item_type", "resp_type"), summarise,
                count = length(participant))

wmresps_agg$prop = wmresps_agg$count/ifelse(wmresps_agg$item_type == "new-new", 10 + 6*4, 10)

resp_tables = with(wm_dat, table(resp_type, item_type, group))

# proportions
resp_propall = resp_tables
resp_propall[,,"younger"] = t(t(resp_propall[,,"younger"])/ apply(resp_propall[,,"younger"], 2, sum))
resp_propall[,,"older"] = t(t(resp_propall[,,"older"])/ apply(resp_propall[,,"older"], 2, sum))

resp_propin = resp_propall[c("extra", "ltm", "omission", "previous", "within"),,]

```

# Summary

Here is all of the proactive data we have collected online so far. Each session was made up of two parts:

1. **Learning:** Participants learned 30 image-word associations that were initially presented in study-test blocks of 10 pairs. Each pair was presented for 4 seconds with a .5 second ISI. Following 10 pairs participants were cued to recall words in a random order with each associated image. During this part of the experiment participants were given feedback. The recalled word was presented for .5 seconds in green text if it was correct or red if incorrect. If incorrect, the correct word was then presented with the cue image for restudy for 4 seconds. During the initial phase of learning participants looped through all 30 pairs and if their accuracy across all pairs was under 80% they would loop though the 30 pairs again (3 groups of 10). This continued until the participant got 80% or more correct or 3 loops had been completed (this is referred to as block 1, 2, and 3 in the figure below). Following this there was a final test of learning in which all 30 pairs were cued in a random order. 

2. **Working Memory:** There were 16 working memory trials in which participants were presented with 4 to-be-remembered image-word pairs. For 10 of the trials each pair was a different type (presented in random order). Match items were identical to a previously learned pair, mis-match items were a recombination of a previously learned image and word, old-new items presented a learned image with a new word, and for new-new items both image and word had not previously been seen. For 6 of the trials all 4 pairs were new-new. Each pair was presented for 2 seconds with a .5 second ISI. Following a retention interval memory for the 4 pairs was probed by presenting each cue image in a random order. No feedback was given in this part. 

For the working memory task there are 4 conditions that differ in the length of the retention interval between study and test (2 or 10 s) and in the presence or absence of a distracting task (search). In the 2 s interval condition there was one search problem to respond to whereas in the 10 s condition there were four. 

# Participants

The table below gives the number of participants (who provided complete data sets) in each condition/group and their ages.

```{r}

info_tab = ddply(info, c("interval", "distraction", "group"), summarize,
                 N = length(age),
                 N_female = sum(Sex == "Female"),
                 M_age = mean(age), 
                 SD_age = sd(age),
                 min_age = min(age),
                 max_age = max(age)#,
                 # N_CA = sum(Nationality == "Canada"),
                 # N_US = sum(Nationality == "United States"),
                 # N_UK = sum(Nationality == "United Kingdom")
)

knitr::kable(info_tab, digits = 2)
```

# Learning

```{r, fig.width=7, fig.height=4}

# find bad performers
learn_overall = ddply(learn_dat, c("participant", "interval", "distraction", "group"),
                      summarize,
                  N = length(recall_acc), 
                  acc = mean(recall_acc),
                  mean_rt = mean(recalled_rt),
                  prop_noresp = mean(recalled %in% c("?", "")))

#learn_overall[learn_overall$acc < .5,]

learn_agg = ddply(learn_dat, c("participant", "interval", "distraction", "group", "learn_block"), summarize,
                  N = length(recall_acc), 
                  acc = mean(recall_acc),
                  mean_rt = mean(recalled_rt),
                  prop_noresp = mean(recalled %in% c("?", "")))

learn_agg$learn_block = factor(learn_agg$learn_block, levels = c("1", "2", "3", "final test"))

learn_mse = summarySEwithin(data = learn_agg, measurevar = "acc", betweenvars = c("interval", "distraction", "group"), withinvars = "learn_block")


### plot 1: overall performance in each learning block + final test performance

jitts = c("younger" = -.08, "older" = .08)
cols = c("younger" = "deepskyblue4", "older" = "firebrick")

par(mfcol=c(2,2), mar=c(2,2,2,2), oma=c(0,2,0,0))

for (i in intervals){
  for (d in distractions){
    plot(NA, xlim=c(.7,4.3), ylim=c(0,1), xlab="", ylab="Recall Accuracy", axes=F)
    #box()
    axis(1, at = 1:4, labels = c("Block 1", "Block 2", "Block 3", "Final Test"))
    axis(2)
    mtext(paste(i, c("with distraction", "no distraction")[(d=="no")+1]), adj = 0)
    
    for (g in groups){
        l_ply(.data = ids[[i]][[d]][[g]], .fun = function(x) with(subset(learn_agg, participant==x), points(jitter(as.numeric(learn_block)+jitts[g], amount = .025), acc, pch=16, col=faintCol(cols[g]), type='p')))
    }
    for (g in groups){
      # error bars
      with(subset(learn_mse, distraction==d & interval==i & group==g), errBars(means = acc, error = se, xpos = as.numeric(learn_block)+jitts[g]))
      # points
      with(subset(learn_mse, distraction==d & interval==i & group==g), points(as.numeric(learn_block)+jitts[g], acc, pch=16, col=cols[g], type='b'))
    }
  }
}

legend("bottomright", legend = groups, pch=16, col=cols, bty='n')

#mtext("Recall accuracy for learning phase", font=2, line=-1, adj=0, outer = T)

mtext("Learning Accuracy", 2, outer = T)

# mtext("(Note: participants kept doing blocks\nuntil they got 80% or had done 3)", side = 1, line=1, adj=0, outer=T)

```

The figure above shows recall performance during the learning phase of the experiment. Data are presented separately for the different conditions but this phase of the experiment was identical. Any differences are presumably due to allocation of younger/older participants to condition.

```{r}
# knitr::kable(with(learn_agg, table(interval, distraction, group, learn_block)))
```

```{r learn-analysis, cache=T}
## analysis
# compare final learning performance

LOAD = T

learn_dat = within(learn_dat, {
  distraction = as.factor(distraction)
  interval = as.factor(interval)
  group = as.factor(group)
})

options(contrasts=c("contr.sum", "contr.sum"))

# contrasts(learn_dat$distraction)
# contrasts(learn_dat$interval)
# contrasts(learn_dat$group)

if (!LOAD){
  learn_m1 = glmer(recall_acc ~ distraction*interval*group + (1 | participant),
                 data = subset(learn_dat, learn_block=="final test"),
                 family = binomial(link = "logit"))
  
  saveRDS(learn_m1, file = "rds-files/learn_m1.rds")
  
  ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## 
  # brms
  # priors
  priors = c(set_prior("cauchy(0, 2.5)", class = "Intercept"),
             set_prior("cauchy(0, 2.5)", class = "b"),
             set_prior("cauchy(0, 2.5)", class = "sd"))
  
  learn_dat$word_fac = as.factor(learn_dat$word)
  
  # strict scoring
  learn_brm1 = brm(recall_acc ~ distraction*interval*group + 
                     (1 | participant) + (1 | word_fac), 
                   data = subset(learn_dat, learn_block=="final test"), 
                   family = bernoulli(link = "logit"), 
                   prior = priors, save_all_pars = T)
  
  saveRDS(learn_brm1, file = "rds-files/learn_brm1.rds")
  
} else {
  learn_m1 = readRDS("rds-files/learn_m1.rds")
}


# summary(learn_m1)

learn_m1_an = car::Anova(learn_m1)

```

Recall accuracy in the final test phase was analyzed with a generalized (logistic) linear mixed effects model (see below).

```{r}
knitr::kable(learn_m1_an, digits = 2, caption = "Fixed effects tests (Wald Chi squared) for recall accuracy in the final test of learning.")
```

There is a clear group difference in accuracy, `r print_chi(learn_m1_an, 3)`:

```{r}
aggregate(acc ~ group, data = subset(learn_agg, learn_block == "final test"), FUN = function(x) round(mean(x), 2))
```

There is also a difference between the interval conditions in final learning accuracy, `r print_chi(learn_m1_an, 2)`, with slightly better performance for participants in the 10 s condition:

```{r}
aggregate(acc ~ interval, data = subset(learn_agg, learn_block == "final test"), FUN = function(x) round(mean(x), 2))
```

# Working Memory

The figure below shows recall accuracy by item type for the four conditions. The results of analysis are presented in the table below.

```{r, fig.width=7, fig.height=4}

wm_overall = ddply(wm_dat, c("participant", "interval", "distraction", "group"), summarize,
                   N = length(recall_acc),
                   acc = mean(recall_acc),
                   mean_rt = mean(recall_rt))

# hist(wm_overall$acc)
# wm_overall[wm_overall$acc <.2,]


wm_agg = ddply(wm_dat, c("participant", "interval", "distraction", "group", "item_type"), summarize,
               N = length(recall_acc),
               acc = mean(recall_acc),
               mean_rt = mean(recall_rt),
               ltm_int = mean(ltm_intru))

wm_agg$item_type = as.factor(wm_agg$item_type)

wm_mse = summarySEwithin(data = wm_agg, measurevar = "acc", betweenvars = c("interval", "distraction", "group"), withinvars = "item_type")

### plot 2: performance in the wm task by item type

par(mfcol=c(2,2), mar=c(2,2,2,2), oma=c(0,2,0,0))

for (i in intervals){
  for (d in distractions){
    plot(NA, xlim=c(.7,4.3), ylim=c(0,1), xlab="", ylab="Recall Accuracy", axes=F)
    #box()
    labs = levels(wm_agg$item_type)
    labs[labs=="new-new"]="new"
    axis(1, at = 1:4, labels = labs)
    axis(2)
    mtext(paste(i, c("with distraction", "no distraction")[(d=="no")+1]), adj = 0)
    
    for (g in groups){
        l_ply(.data = ids[[i]][[d]][[g]], .fun = function(x) with(subset(wm_agg, participant==x), points(jitter(as.numeric(item_type)+jitts[g], amount = .025), acc, pch=16, col=faintCol(cols[g]), type='p')))
    }
    for (g in groups){
      # error bars
      with(subset(wm_mse, distraction==d & interval==i & group==g), errBars(means = acc, error = se, xpos = as.numeric(item_type)+jitts[g]))
      # points
      with(subset(wm_mse, distraction==d & interval==i & group==g), points(as.numeric(item_type)+jitts[g], acc, pch=16, col=cols[g], type='b'))
    }
  }
}

legend("bottomright", legend = groups, pch=16, col=cols, bty='n')

#mtext("Working memory performance by item type", font=2, line=-1, adj=0, outer=T)

mtext("WM Accuracy", 2, outer = T)

```

```{r wm-analysis}
# # analysis
LOAD=T

wm_dat = within(wm_dat, {
  distraction = as.factor(distraction)
  interval = as.factor(interval)
  group = as.factor(group)
  item_type = as.factor(item_type)
})

options(contrasts=c("contr.sum", "contr.sum"))

# contrasts(wm_dat$distraction)
# contrasts(wm_dat$interval)
# contrasts(wm_dat$group)

contrasts(wm_dat$item_type) = cbind(matchVrest = c(1,-1/3,-1/3,-1/3),
                                        newVnonmatch=c(0,-1/2,1,-1/2),
                                        mismatchVoldnew=c(0,1,0,-1))

if (!LOAD){
  wm_m1 = glmer(recall_acc ~ 1 + distraction*interval*group*item_type + 
                (1 + item_type | participant),
              data = wm_dat,
              family = binomial(link = "logit"))
  
  # follow up - separate groups
  wm_m1_y = glmer(recall_acc ~ 1 + distraction*interval*item_type + 
                    (1 + item_type | participant),
                  data = subset(wm_dat, group=="younger"),
                  family = binomial(link = "logit"))
  
  wm_m1_o = glmer(recall_acc ~ 1 + distraction*interval*item_type + 
                    (1 + item_type | participant),
                  data = subset(wm_dat, group=="older"),
                  family = binomial(link = "logit"))

  saveRDS(wm_m1, file = "rds-files/wm_m1.rds")
  saveRDS(wm_m1_y, file = "rds-files/wm_m1_y.rds")
  saveRDS(wm_m1_o, file = "rds-files/wm_m1_o.rds")
  
  ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## 
  # brms
  wm_dat$word_fac = as.factor(wm_dat$word)
  
  # priors
  priors = c(set_prior("cauchy(0, 2.5)", class = "Intercept"),
             set_prior("cauchy(0, 2.5)", class = "b"),
             set_prior("cauchy(0, 2.5)", class = "sd"),
             set_prior("lkj(1)", class = "cor"))
  
  wm_brm1 = brm(recall_acc ~ distraction*interval*group*item_type + 
                  (1 + item_type | participant) + (1 | word_fac), 
                data = wm_dat, 
                family = bernoulli(link = "logit"), 
                prior = priors, save_all_pars = T)
  
  #wm_ml1 = bridge_sampler(wm_brm1) # ^^^ need more samples...
  
  saveRDS(wm_brm1, file = "rds-files/wm_brm1.rds")
  #saveRDS(wm_ml1, file = "rds-files/wm_ml1.rds")
  
  #wm_m2 = update(wm_m1, .~. -item_type:group)
  
} else {
  wm_m1 = readRDS("rds-files/wm_m1.rds")
  wm_m1_y = readRDS("rds-files/wm_m1_y.rds")
  wm_m1_o = readRDS("rds-files/wm_m1_o.rds")
  
  # wm_brm1 = readRDS("rds-files/wm_brm1.rds")
}

#summary(wm_m1)

wm_m1_an = car::Anova(wm_m1)

```

```{r}
knitr::kable(wm_m1_an, digits = 2, caption = "Fixed effects tests (Wald Chi squared) for recall accuracy in the working memory task.")
```

There is an effect of distraction, `r print_chi(wm_m1_an, 1)`, with slightly lower performance with the distracting task:

```{r}
aggregate(acc ~ distraction, data = wm_agg, FUN = function(x) round(mean(x), 2))
```

The effect of interval, `r print_chi(wm_m1_an, 2)`, is down to better performance with a 10 s interval vs. 2 s:

```{r}
aggregate(acc ~ interval, data = wm_agg, FUN = function(x) round(mean(x), 2))
```

The two age groups differ in the expected direction, `r print_chi(wm_m1_an, 3)`:

```{r}
aggregate(acc ~ group, data = wm_agg, FUN = function(x) round(mean(x), 2))
```

For item type, there is a significant main effect, `r print_chi(wm_m1_an, 4)`, with the only significant contrast being match vs. others, `r print_coef(wm_m1, 5)` (new vs. mismatch/old-new: `r print_coef(wm_m1, 6)`; mismatch vs. old-new: `r print_coef(wm_m1, 7)`)

```{r}
aggregate(acc ~ item_type, data = wm_agg, FUN = function(x) round(mean(x), 2))
```

The effect of item type was modified by two interactions; one with distraction and the other with age group. For the item type by distraction interaction, the driver was the contrast of match items vs. the rest, `r print_coef(wm_m1, "distraction1:item_typematchVrest")`. The contrasts of new vs. recombined pairs, `r print_coef(wm_m1, "distraction1:item_typenewVnonmatch")`, and mismatch vs. old-new, `r print_coef(wm_m1, "distraction1:item_typemismatchVoldnew")`, were both not significant. Means are given below and show that the benefit of match pairs to performance is larger with distraction (or that the effect of distraction was weakest for match pairs):

```{r}
aggregate(acc ~ item_type + distraction, data = wm_agg, FUN = function(x) round(mean(x), 2))
```

For the interaction of age group and item type the driver was the contrast of new pairs with recombined pairs (mismatch/old-new), `r print_coef(wm_m1, "group1:item_typenewVnonmatch")`. The match vs. rest, `r print_coef(wm_m1, "group1:item_typematchVrest")`, and mismatch vs. old-new contrasts, `r print_coef(wm_m1, "group1:item_typemismatchVoldnew")`, were both not significantly moderated by age.

To follow up on this, separate models were fit to the data from younger and older adults. For younger adults the new vs. recombined contrast suggested better performance for mismatch and old-new pairs relative to new, `r print_coef(wm_m1_y, "item_typenewVnonmatch")`, whereas for older adults the opposite is the case, `r print_coef(wm_m1_o, "item_typenewVnonmatch")`. This is seen in the pattern of means below:

```{r}
aggregate(acc ~ item_type + group, data = wm_agg, FUN = function(x) round(mean(x), 2))
```

None of the remaining interactions were significant (see table above).

# Conclusions

- Older adults show some evidence of PI whereas younger adults perform slightly better when pairs are made up of recombined learned elements (mismatch and old-new pairs) relative to the new pair baseline
- The degree of proactive facilitation (benefit for match pairs) appears to be similar across the two age groups
- The length of the retention interval (2-10 s) and presence of distraction (search) do not appear to influence the magnitude of age differences in PI or PF
- PF is stronger with distraction overall

# Additional Analyses

```{r}
### ltm intrusions
wm_mse_ltm = summarySEwithin(data = subset(wm_agg, item_type %in% c("mis-match", "old-new")), measurevar = "ltm_int", betweenvars = c("interval", "distraction", "group"), withinvars = "item_type")

wm_mse_ltm = droplevels(wm_mse_ltm)

wm_agg2 = droplevels(subset(wm_agg, item_type %in% c("mis-match", "old-new")))


par(mfcol=c(2,2), mar=c(2,2,2,2), oma=c(0,2,0,0))

for (i in intervals){
  for (d in distractions){
    plot(NA, xlim=c(.7,2.3), ylim=c(0,max(wm_agg2$ltm_int, na.rm = T)), xlab="", ylab="Recall Accuracy", axes=F)
    #box()
    labs = levels(wm_mse_ltm$item_type)
    axis(1, at = 1:2, labels = labs)
    axis(2)
    mtext(paste(i, c("with distraction", "no distraction")[(d=="no")+1]), adj = 0)
    
    for (g in groups){
        l_ply(.data = ids[[i]][[d]][[g]], .fun = function(x) with(subset(wm_agg2, participant==x), points(jitter(as.numeric(item_type)+jitts[g], amount = .025), ltm_int, pch=16, col=faintCol(cols[g]), type='p')))
    }
    for (g in groups){
      # error bars
      with(subset(wm_mse_ltm, distraction==d & interval==i & group==g), errBars(means = ltm_int, error = se, xpos = as.numeric(item_type)+jitts[g]))
      # points
      with(subset(wm_mse_ltm, distraction==d & interval==i & group==g), points(as.numeric(item_type)+jitts[g], ltm_int, pch=16, col=cols[g], type='b'))
    }
  }
}

legend("topright", legend = groups, pch=16, col=cols, bty='n')

mtext("Proportion LTM Intrusions", 2, outer = T)

```

```{r intru-analysis}
# # analysis
LOAD=T

wm_dat2 = droplevels(subset(wm_dat, item_type %in% c("mis-match", "old-new")))

options(contrasts=c("contr.sum", "contr.sum"))

# contrasts(wm_dat2$distraction)
# contrasts(wm_dat2$interval)
# contrasts(wm_dat2$group)
# contrasts(wm_dat2$item_type)

if (!LOAD){
  # just intrusions
  intru_m1 = glmer(ltm_intru ~ 1 + distraction*interval*group*item_type + 
                (1 + item_type | participant),
              data = wm_dat2,
              family = binomial(link = "logit"))

  saveRDS(intru_m1, file = "rds-files/intru_m1.rds")
  
  ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## 
  # brms 
  # just intrusions 
  wm_dat2$word_fac = as.factor(wm_dat2$word)
  
  # priors
  priors = c(set_prior("cauchy(0, 2.5)", class = "Intercept"),
             set_prior("cauchy(0, 2.5)", class = "b"),
             set_prior("lkj(1)", class = "cor"))
  
  intru_brm1 = brm(ltm_intru ~ distraction*interval*group*item_type + 
                  (1 + item_type | participant) + (1 | word_fac), 
                data = wm_dat2, 
                family = bernoulli(link = "logit"), 
                prior = priors, save_all_pars = T,
                control=list(max_treedepth=15))
  
  saveRDS(intru_brm1, file = "rds-files/intru_brm1.rds")
  
  # categorical model with all responses
  priors = c(set_prior("cauchy(0, 2.5)", class = "Intercept"),
             set_prior("cauchy(0, 2.5)", class = "b"),
             set_prior("cauchy(0, 2.5)", class = "sd", 
                       coef = "Intercept", group = "participant", dpar="muextra"),
             set_prior("cauchy(0, 2.5)", class = "sd", 
                       coef = "item_type1", group = "participant", dpar="muextra"),
             set_prior("cauchy(0, 2.5)", class = "sd", 
                       coef = "Intercept", group = "word_fac", dpar="muextra"),
             set_prior("cauchy(0, 2.5)", class = "sd", 
                       coef = "Intercept", group = "participant", dpar="multm"),
             set_prior("cauchy(0, 2.5)", class = "sd", 
                       coef = "item_type1", group = "participant", dpar="multm"),
             set_prior("cauchy(0, 2.5)", class = "sd", 
                       coef = "Intercept", group = "word_fac", dpar="multm"),
             set_prior("cauchy(0, 2.5)", class = "sd", 
                       coef = "Intercept", group = "participant", dpar="muomission"),
             set_prior("cauchy(0, 2.5)", class = "sd", 
                       coef = "item_type1", group = "participant", dpar="muomission"),
             set_prior("cauchy(0, 2.5)", class = "sd", 
                       coef = "Intercept", group = "word_fac", dpar="muomission"),
             set_prior("cauchy(0, 2.5)", class = "sd", 
                       coef = "Intercept", group = "participant", dpar="muprevious"),
             set_prior("cauchy(0, 2.5)", class = "sd", 
                       coef = "item_type1", group = "participant", dpar="muprevious"),
             set_prior("cauchy(0, 2.5)", class = "sd", 
                       coef = "Intercept", group = "word_fac", dpar="muprevious"),
             set_prior("cauchy(0, 2.5)", class = "sd", 
                       coef = "Intercept", group = "participant", dpar="muwithin"),
             set_prior("cauchy(0, 2.5)", class = "sd", 
                       coef = "item_type1", group = "participant", dpar="muwithin"),
             set_prior("cauchy(0, 2.5)", class = "sd", 
                       coef = "Intercept", group = "word_fac", dpar="muwithin"),
             set_prior("lkj(1)", class = "cor"))
  
  wmcat_brm1 = brm(resp_type ~ distraction*interval*group*item_type + 
                  (1 + item_type | participant) + (1 | word_fac), 
                data = wm_dat2, 
                family = categorical(link = "logit"), 
                prior = priors, save_all_pars = T,
                control=list(max_treedepth=15))
  
  saveRDS(wmcat_brm1, file = "rds-files/wmcat_brm1.rds")
  
} else {
  intru_m1 = readRDS("rds-files/intru_m1.rds")
  
  # intru_brm1 = readRDS("rds-files/intru_brm1.rds")
}

#summary(wm_m1)

intru_m1_an = car::Anova(intru_m1)

```


```{r, fig.height=4, fig.width=8}
# proportions of response types

par(mfrow=c(1,2), mar=c(3,3,1,1))
barplot(resp_propall[,,"younger"], ylim=c(0,1), beside = T, legend.text = F, cex.names = .8, col = viridis::viridis(6), main = "younger")
barplot(resp_propall[,,"older"],  ylim=c(0,1), beside = T, legend.text = T, cex.names = .8, col = viridis::viridis(6), main = "older")

```

```{r, fig.height=4, fig.width=8}
# proportions of response types (just errors)

par(mfrow=c(1,2), mar=c(3,3,1,1))
barplot(resp_propin[,,"younger"], ylim=c(0,max(resp_propin[,,"younger"])), beside = T, legend.text = F, cex.names = .8, col = viridis::viridis(6)[2:6], main = "younger")
barplot(resp_propin[,,"older"],  ylim=c(0,max(resp_propin[,,"older"])), beside = T, legend.text = F, cex.names = .8, col = viridis::viridis(6)[2:6], main = "older")

```


```{r}

# MULTIVARIATE MODEL WITH LEARNING AND WM DATA
# https://github.com/paul-buerkner/brms/issues/360

# combine the data sets to fit a mv model
# just use final learning data
learn_final = subset(learn_dat, learn_block == "final test")

wm_dat$learn_block = "0"
learn_final$item_type = "match"

# indicators for subsetting/weighting analyses (see link above)
wm_dat$wm = 1; learn_final$wm = 0
wm_dat$learn = 0; learn_final$learn = 1

multicols = c("participant", "word", "group", "learn_block", "item_type", 
              "recall_acc", "wm", "learn")
multidat = rbind(wm_dat[,multicols], learn_final[,multicols])

# factors
multidat$word_fac = as.factor(multidat$word)
# multidat$block_loop = as.factor(multidat$block_loop)
multidat$participant = as.factor(multidat$participant)
multidat$item_type = as.factor(multidat$item_type)

# responses need to be different columns
multidat$acc_wm = multidat$recall_acc
multidat$acc_learn = multidat$recall_acc

# contrasts
contrasts(multidat$item_type) = cbind(matchVrest = c(1,-1/3,-1/3,-1/3),
                                        newVnonmatch=c(0,-1/2,1,-1/2),
                                        mismatchVoldnew=c(0,1,0,-1))

# contrasts(multidat$item_type) = cbind(match = c(1,0,-1,0), 
#                                         mis=c(0,1,-1,0), 
#                                         oldnew=c(0,0,-1,1))

# contrasts(multidat$block_loop) = cbind(b2 = c(-1,1,0), 
#                                          final=c(-1,0,1))

contrasts(multidat$group) = c(-1,1)

if (!LOAD){
  multi_form = mvbf(
    ## ADD TYPE BY GROUP INTERACTION?
    bf(acc_wm | subset(wm) ~ item_type + group + (1 + item_type |p| participant), 
       family = bernoulli()),
    bf(acc_learn | subset(learn) ~ group + (1 |p| participant), 
       family = bernoulli()), 
    rescor = F
  )
  
  get_prior(multi_form, data = multidat)
  
  multi_priors = c(set_prior("cauchy(0, 2.5)", class = "Intercept"),
                   set_prior("cauchy(0, 2.5)", class = "Intercept", resp = "acclearn"),
                   set_prior("cauchy(0, 2.5)", class = "Intercept", resp = "accwm"),
                   set_prior("cauchy(0, 2.5)", class = "b"),
                   set_prior("cauchy(0, 2.5)", class = "b", resp = "acclearn"),
                   set_prior("cauchy(0, 2.5)", class = "b", resp = "accwm"),
                   set_prior("cauchy(0, 2.5)", class = "sd", resp = "acclearn"),
                   set_prior("cauchy(0, 2.5)", class = "sd", resp = "accwm"),
                   set_prior("lkj(1)", class = "cor"))
  
  multi_m1 = brm(multi_form, data = multidat, prior = multi_priors,
                 control=list(adapt_delta=0.9))
  
  saveRDS(multi_m1, file = "rds-files/multi_m1.rds")
  
} else {
  multi_m1 = readRDS("rds-files/multi_m1.rds")
}

```


```{r}
labs = c("cor(WM intercept, WM match vs. rest)", 
         "cor(WM intercept, WM new vs. non-match)",
         "cor(WM match vs. rest, WM new vs. non-match)",
         "cor(WM intercept, WM mis-match vs. old-new)",
         "cor(WM match vs. rest, WM mis-match vs. old-new)",
         "cor(WM new vs. non-match, WM mis-match vs. old-new)",
         "cor(WM intercept, Learn intercept)",
         "cor(WM match vs. rest, Learn intercept)",
         "cor(WM new vs. non-match, Learn intercept)",
         "cor(WM mis-match vs. old-new, Learn intercept)")

p = stanplot(multi_m1, pars = "cor")
p + ggplot2::scale_x_continuous(limits = c(-1,1)) + 
  ggplot2::scale_y_discrete(breaks=p$data$parameter, labels = labs)

```